{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSpnWBP5ELSI"
      },
      "source": [
        "# 実践演習 Day 1：streamlitとFastAPIのデモ\n",
        "このノートブックでは以下の内容を学習します。\n",
        "\n",
        "- 必要なライブラリのインストールと環境設定\n",
        "- Hugging Faceからモデルを用いたStreamlitのデモアプリ\n",
        "- FastAPIとngrokを使用したAPIの公開方法\n",
        "\n",
        "演習を始める前に、HuggingFaceとngrokのアカウントを作成し、\n",
        "それぞれのAPIトークンを取得する必要があります。\n",
        "\n",
        "\n",
        "演習の時間では、以下の3つのディレクトリを順に説明します。\n",
        "\n",
        "1. 01_streamlit_UI\n",
        "2. 02_streamlit_app\n",
        "3. 03_FastAPI\n",
        "\n",
        "2つ目や3つ目からでも始められる様にノートブックを作成しています。\n",
        "\n",
        "復習の際にもこのノートブックを役立てていただければと思います。\n",
        "\n",
        "### 注意事項\n",
        "「02_streamlit_app」と「03_FastAPI」では、GPUを使用します。\n",
        "\n",
        "これらを実行する際は、Google Colab画面上のメニューから「編集」→ 「ノートブックの設定」\n",
        "\n",
        "「ハードウェアアクセラレーター」の項目の中から、「T4 GPU」を選択してください。\n",
        "\n",
        "このノートブックのデフォルトは「CPU」になっています。\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhtHkJOgELSL"
      },
      "source": [
        "# 環境変数の設定（1~3共有）\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-FjBp4MMQHM"
      },
      "source": [
        "GitHubから演習用のコードをCloneします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AIXMavdDEP8U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "deb991dc-af64-45a0-91c3-6bc255f3214d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'lecture-ai-engineering'...\n",
            "remote: Enumerating objects: 41, done.\u001b[K\n",
            "remote: Counting objects: 100% (32/32), done.\u001b[K\n",
            "remote: Compressing objects: 100% (27/27), done.\u001b[K\n",
            "remote: Total 41 (delta 7), reused 5 (delta 5), pack-reused 9 (from 1)\u001b[K\n",
            "Receiving objects: 100% (41/41), 34.04 KiB | 1.36 MiB/s, done.\n",
            "Resolving deltas: 100% (7/7), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/matsuolab/lecture-ai-engineering.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XC8n7yZ_vs1K"
      },
      "source": [
        "必要なAPIトークンを.envに設定します。\n",
        "\n",
        "「lecture-ai-engineering/day1」の配下に、「.env_template」ファイルが存在しています。\n",
        "\n",
        "隠しファイルのため表示されていない場合は、画面左側のある、目のアイコンの「隠しファイルの表示」ボタンを押してください。\n",
        "\n",
        "「.env_template」のファイル名を「.env」に変更します。「.env」ファイルを開くと、以下のような中身になっています。\n",
        "\n",
        "\n",
        "```\n",
        "HUGGINGFACE_TOKEN=\"hf-********\"\n",
        "NGROK_TOKEN=\"********\"\n",
        "```\n",
        "ダブルクオーテーションで囲まれた文字列をHuggingfaceのアクセストークンと、ngrokの認証トークンで書き変えてください。\n",
        "\n",
        "それぞれのアカウントが作成済みであれば、以下のURLからそれぞれのトークンを取得できます。\n",
        "\n",
        "- Huggingfaceのアクセストークン\n",
        "https://huggingface.co/docs/hub/security-tokens\n",
        "\n",
        "- ngrokの認証トークン\n",
        "https://dashboard.ngrok.com/get-started/your-authtoken\n",
        "\n",
        "書き換えたら、「.env」ファイルをローカルのPCにダウンロードしてください。\n",
        "\n",
        "「01_streamlit_UI」から「02_streamlit_app」へ進む際に、CPUからGPUの利用に切り替えるため、セッションが一度切れてしまいます。\n",
        "\n",
        "その際に、トークンを設定した「.env」ファイルは再作成することになるので、その手間を減らすために「.env」ファイルをダウンロードしておくと良いです。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Py1BFS5RqcSS"
      },
      "source": [
        "「.env」ファイルを読み込み、環境変数として設定します。次のセルを実行し、最終的に「True」が表示されていればうまく読み込めています。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bvEowFfg5lrq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d7b6039-dc82-4816-df9e-1f48d32db774"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.1.0\n",
            "/content/lecture-ai-engineering/day1\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "!pip install python-dotenv\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "\n",
        "%cd /content/lecture-ai-engineering/day1\n",
        "load_dotenv(find_dotenv())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "os0Yk6gaELSM"
      },
      "source": [
        "# 01_streamlit_UI\n",
        "\n",
        "ディレクトリ「01_streamlit_UI」に移動します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "S28XgOm0ELSM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bc68dfe-7704-4a80-915d-a7816b8aa0c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/lecture-ai-engineering/day1/01_streamlit_UI\n"
          ]
        }
      ],
      "source": [
        "%cd /content/lecture-ai-engineering/day1/01_streamlit_UI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVp-aEIkELSM"
      },
      "source": [
        "必要なライブラリをインストールします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "nBe41LFiELSN"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yyw6VHaTELSN"
      },
      "source": [
        "ngrokのトークンを使用して、認証を行います。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "aYw1q0iXELSN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a01df79b-aa12-49f2-e3b3-09ab6ccf748a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ],
      "source": [
        "!ngrok authtoken $$NGROK_TOKEN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RssTcD_IELSN"
      },
      "source": [
        "アプリを起動します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "f-E7ucR6ELSN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3915c730-c3d6-4900-85cd-5fba3cbab2f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "公開URL: https://3911-34-34-86-123.ngrok-free.app\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.34.86.123:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "public_url = ngrok.connect(8501).public_url\n",
        "print(f\"公開URL: {public_url}\")\n",
        "!streamlit run app.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbYyXVFjELSN"
      },
      "source": [
        "公開URLの後に記載されているURLにブラウザでアクセスすると、streamlitのUIが表示されます。\n",
        "\n",
        "app.pyのコメントアウトされている箇所を編集することで、UIがどの様に変化するか確認してみましょう。\n",
        "\n",
        "streamlitの公式ページには、ギャラリーページがあります。\n",
        "\n",
        "streamlitを使うとpythonという一つの言語であっても、様々なUIを実現できることがわかると思います。\n",
        "\n",
        "https://streamlit.io/gallery"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmtP5GLOELSN"
      },
      "source": [
        "後片付けとして、使う必要のないngrokのトンネルを削除します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "8Ek9QgahELSO"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok\n",
        "ngrok.kill()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-T8tFpyELSO"
      },
      "source": [
        "# 02_streamlit_app"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqogFQKnELSO"
      },
      "source": [
        "\n",
        "ディレクトリ「02_streamlit_app」に移動します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "UeEjlJ7uELSO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62ab42ac-b127-4d36-ba82-0dfd53fc3d12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/lecture-ai-engineering/day1/02_streamlit_app\n"
          ]
        }
      ],
      "source": [
        "%cd /content/lecture-ai-engineering/day1/02_streamlit_app"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XUH2AstELSO"
      },
      "source": [
        "必要なライブラリをインストールします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "mDqvI4V3ELSO"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZO31umGZELSO"
      },
      "source": [
        "ngrokとhuggigfaceのトークンを使用して、認証を行います。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "jPxTiEWQELSO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d3b77d3-7a48-4d7c-92f9-1906280d7dbe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n",
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: read).\n",
            "The token `read-token_AIeng_tokyoUT` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `read-token_AIeng_tokyoUT`\n"
          ]
        }
      ],
      "source": [
        "!ngrok authtoken $$NGROK_TOKEN\n",
        "!huggingface-cli login --token $$HUGGINGFACE_TOKEN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dz4WrELLELSP"
      },
      "source": [
        "stramlitでHuggingfaceのトークン情報を扱うために、streamlit用の設定ファイル（.streamlit）を作成し、トークンの情報を格納します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "W184-a7qFP0W"
      },
      "outputs": [],
      "source": [
        "# .streamlit/secrets.toml ファイルを作成\n",
        "import os\n",
        "import toml\n",
        "\n",
        "# 設定ファイルのディレクトリ確保\n",
        "os.makedirs('.streamlit', exist_ok=True)\n",
        "\n",
        "# 環境変数から取得したトークンを設定ファイルに書き込む\n",
        "secrets = {\n",
        "    \"huggingface\": {\n",
        "        \"token\": os.environ.get(\"HUGGINGFACE_TOKEN\", \"\")\n",
        "    }\n",
        "}\n",
        "\n",
        "# 設定ファイルを書き込む\n",
        "with open('.streamlit/secrets.toml', 'w') as f:\n",
        "    toml.dump(secrets, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fK0vI_xKELSP"
      },
      "source": [
        "アプリを起動します。\n",
        "\n",
        "02_streamlit_appでは、Huggingfaceからモデルをダウンロードするため、初回起動には2分程度時間がかかります。\n",
        "\n",
        "この待ち時間を利用して、app.pyのコードを確認してみましょう。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "TBQyTTWTELSP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d99d795-93ac-46d0-e83e-8f7d111182d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "公開URL: https://1457-35-221-183-159.ngrok-free.app\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.221.183.159:8501\u001b[0m\n",
            "\u001b[0m\n",
            "NLTK loaded successfully.\n",
            "2025-04-22 18:16:20.543207: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1745345780.722636    2592 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1745345780.773028    2592 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-04-22 18:16:21.156910: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "NLTK Punkt data checked/downloaded.\n",
            "Database 'chat_feedback.db' initialized successfully.\n",
            "Data saved to DB successfully.\n",
            "Data saved to DB successfully.\n",
            "Data saved to DB successfully.\n",
            "Data saved to DB successfully.\n",
            "Data saved to DB successfully.\n",
            "Data saved to DB successfully.\n",
            "Data saved to DB successfully.\n",
            "Data saved to DB successfully.\n",
            "Data saved to DB successfully.\n",
            "Data saved to DB successfully.\n",
            "config.json: 100% 805/805 [00:00<00:00, 3.86MB/s]\n",
            "model.safetensors.index.json: 100% 24.2k/24.2k [00:00<00:00, 82.9MB/s]\n",
            "Fetching 2 files:   0% 0/2 [00:00<?, ?it/s]\n",
            "model-00001-of-00002.safetensors:   0% 0.00/4.99G [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:   0% 0.00/241M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   0% 10.5M/4.99G [00:00<05:34, 14.9MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:   4% 10.5M/241M [00:00<00:09, 24.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:   9% 21.0M/241M [00:00<00:09, 24.4MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   0% 21.0M/4.99G [00:01<06:12, 13.3MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  13% 31.5M/241M [00:01<00:08, 24.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  17% 41.9M/241M [00:01<00:08, 24.6MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 31.5M/4.99G [00:02<06:32, 12.6MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  22% 52.4M/241M [00:02<00:07, 24.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  26% 62.9M/241M [00:02<00:07, 24.6MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 41.9M/4.99G [00:03<06:39, 12.4MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  30% 73.4M/241M [00:02<00:06, 24.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  35% 83.9M/241M [00:03<00:06, 24.6MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 52.4M/4.99G [00:03<06:09, 13.4MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  39% 94.4M/241M [00:03<00:05, 24.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  44% 105M/241M [00:04<00:05, 24.6MB/s] \u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 62.9M/4.99G [00:04<06:22, 12.9MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  48% 115M/241M [00:04<00:05, 24.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  52% 126M/241M [00:05<00:04, 24.6MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 73.4M/4.99G [00:05<05:59, 13.7MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  57% 136M/241M [00:05<00:04, 24.6MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 83.9M/4.99G [00:06<05:43, 14.3MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  61% 147M/241M [00:05<00:03, 24.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  65% 157M/241M [00:06<00:03, 24.6MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 94.4M/4.99G [00:07<06:01, 13.5MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  70% 168M/241M [00:06<00:02, 24.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  74% 178M/241M [00:07<00:02, 24.6MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 105M/4.99G [00:07<05:44, 14.2MB/s] \u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  78% 189M/241M [00:07<00:02, 24.6MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 115M/4.99G [00:08<05:32, 14.6MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  83% 199M/241M [00:08<00:01, 24.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  87% 210M/241M [00:08<00:01, 24.6MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 126M/4.99G [00:09<05:24, 15.0MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  91% 220M/241M [00:08<00:00, 24.6MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 136M/4.99G [00:09<05:18, 15.2MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  96% 231M/241M [00:09<00:00, 24.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors: 100% 241M/241M [00:09<00:00, 24.5MB/s]\n",
            "\n",
            "model-00001-of-00002.safetensors:   3% 147M/4.99G [00:10<05:14, 15.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 157M/4.99G [00:11<05:10, 15.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 168M/4.99G [00:11<05:08, 15.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 178M/4.99G [00:12<05:07, 15.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 189M/4.99G [00:13<05:04, 15.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 199M/4.99G [00:13<05:03, 15.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 210M/4.99G [00:14<05:02, 15.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 220M/4.99G [00:15<05:05, 15.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 231M/4.99G [00:15<05:03, 15.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 241M/4.99G [00:16<05:23, 14.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 252M/4.99G [00:17<05:15, 15.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 262M/4.99G [00:17<05:09, 15.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 273M/4.99G [00:18<05:05, 15.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 283M/4.99G [00:19<05:01, 15.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 294M/4.99G [00:19<04:37, 16.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 304M/4.99G [00:20<04:40, 16.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 315M/4.99G [00:20<04:42, 16.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 325M/4.99G [00:21<04:44, 16.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 336M/4.99G [00:22<04:45, 16.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 346M/4.99G [00:22<04:45, 16.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 357M/4.99G [00:23<04:20, 17.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 367M/4.99G [00:23<04:27, 17.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 377M/4.99G [00:24<04:08, 18.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 388M/4.99G [00:25<04:16, 17.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 398M/4.99G [00:25<03:59, 19.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 409M/4.99G [00:26<03:59, 19.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 419M/4.99G [00:26<03:57, 19.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 430M/4.99G [00:27<03:43, 20.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 440M/4.99G [00:27<03:34, 21.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 451M/4.99G [00:27<03:26, 21.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 461M/4.99G [00:28<03:21, 22.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 472M/4.99G [00:28<03:17, 22.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 482M/4.99G [00:29<03:14, 23.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 493M/4.99G [00:29<03:14, 23.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 503M/4.99G [00:30<03:12, 23.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 514M/4.99G [00:30<03:10, 23.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 524M/4.99G [00:31<03:09, 23.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 535M/4.99G [00:31<03:11, 23.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 545M/4.99G [00:31<03:09, 23.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 556M/4.99G [00:32<03:08, 23.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 566M/4.99G [00:32<03:07, 23.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 577M/4.99G [00:33<03:07, 23.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 587M/4.99G [00:33<03:06, 23.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 598M/4.99G [00:34<03:05, 23.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 608M/4.99G [00:34<03:05, 23.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 619M/4.99G [00:35<03:05, 23.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 629M/4.99G [00:35<03:04, 23.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 640M/4.99G [00:35<03:03, 23.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 650M/4.99G [00:36<03:03, 23.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 661M/4.99G [00:36<03:03, 23.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 671M/4.99G [00:37<03:02, 23.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 682M/4.99G [00:37<03:01, 23.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 692M/4.99G [00:38<03:01, 23.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 703M/4.99G [00:38<03:00, 23.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 713M/4.99G [00:39<03:00, 23.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 724M/4.99G [00:39<02:59, 23.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 734M/4.99G [00:39<02:58, 23.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 744M/4.99G [00:40<02:59, 23.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 755M/4.99G [00:40<02:58, 23.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 765M/4.99G [00:41<02:57, 23.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 776M/4.99G [00:41<02:57, 23.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 786M/4.99G [00:42<02:56, 23.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 797M/4.99G [00:42<02:56, 23.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 807M/4.99G [00:43<02:57, 23.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 818M/4.99G [00:43<02:56, 23.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 828M/4.99G [00:43<02:56, 23.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 839M/4.99G [00:44<03:03, 22.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 849M/4.99G [00:44<03:02, 22.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 860M/4.99G [00:45<02:59, 23.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 870M/4.99G [00:45<02:57, 23.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 881M/4.99G [00:46<02:56, 23.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 891M/4.99G [00:46<02:55, 23.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 902M/4.99G [00:47<02:54, 23.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 912M/4.99G [00:47<02:53, 23.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 923M/4.99G [00:48<02:52, 23.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 933M/4.99G [00:48<02:51, 23.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 944M/4.99G [00:48<02:50, 23.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 954M/4.99G [00:49<02:50, 23.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 965M/4.99G [00:49<02:50, 23.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 975M/4.99G [00:50<02:49, 23.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 986M/4.99G [00:50<02:48, 23.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 996M/4.99G [00:51<02:48, 23.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 1.01G/4.99G [00:51<02:48, 23.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 1.02G/4.99G [00:51<02:47, 23.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 1.03G/4.99G [00:52<02:47, 23.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 1.04G/4.99G [00:52<02:46, 23.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 1.05G/4.99G [00:53<02:46, 23.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 1.06G/4.99G [00:53<02:45, 23.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 1.07G/4.99G [00:54<02:45, 23.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 1.08G/4.99G [00:54<02:44, 23.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 1.09G/4.99G [00:55<02:44, 23.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 1.10G/4.99G [00:55<02:43, 23.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 1.11G/4.99G [00:55<02:43, 23.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 1.12G/4.99G [00:56<02:42, 23.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 1.13G/4.99G [00:56<02:42, 23.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 1.14G/4.99G [00:57<02:41, 23.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 1.15G/4.99G [00:57<02:41, 23.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 1.16G/4.99G [00:58<02:40, 23.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 1.17G/4.99G [00:58<02:41, 23.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 1.18G/4.99G [00:59<02:40, 23.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 1.20G/4.99G [00:59<02:40, 23.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 1.21G/4.99G [00:59<02:39, 23.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 1.22G/4.99G [01:00<02:38, 23.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 1.23G/4.99G [01:00<02:38, 23.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 1.24G/4.99G [01:01<02:38, 23.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 1.25G/4.99G [01:01<02:37, 23.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 1.26G/4.99G [01:02<02:37, 23.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 1.27G/4.99G [01:02<02:36, 23.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 1.28G/4.99G [01:03<02:36, 23.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 1.29G/4.99G [01:03<02:35, 23.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 1.30G/4.99G [01:03<02:35, 23.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 1.31G/4.99G [01:04<02:34, 23.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 1.32G/4.99G [01:04<02:34, 23.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 1.33G/4.99G [01:05<02:33, 23.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 1.34G/4.99G [01:05<02:33, 23.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 1.35G/4.99G [01:06<02:33, 23.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 1.36G/4.99G [01:06<02:32, 23.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 1.37G/4.99G [01:07<02:32, 23.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 1.38G/4.99G [01:07<02:31, 23.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 1.39G/4.99G [01:07<02:31, 23.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 1.41G/4.99G [01:08<02:30, 23.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 1.42G/4.99G [01:08<02:30, 23.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 1.43G/4.99G [01:09<02:30, 23.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 1.44G/4.99G [01:09<02:29, 23.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 1.45G/4.99G [01:10<02:29, 23.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 1.46G/4.99G [01:10<02:28, 23.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 1.47G/4.99G [01:10<02:28, 23.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 1.48G/4.99G [01:11<02:27, 23.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 1.49G/4.99G [01:11<02:27, 23.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 1.50G/4.99G [01:12<02:27, 23.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 1.51G/4.99G [01:12<02:25, 23.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 1.52G/4.99G [01:13<02:25, 23.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 1.53G/4.99G [01:13<02:25, 23.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 1.54G/4.99G [01:14<02:24, 23.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 1.55G/4.99G [01:14<02:24, 23.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 1.56G/4.99G [01:14<02:24, 23.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 1.57G/4.99G [01:15<02:23, 23.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 1.58G/4.99G [01:15<02:23, 23.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 1.59G/4.99G [01:16<02:22, 23.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 1.60G/4.99G [01:16<02:22, 23.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 1.61G/4.99G [01:17<02:21, 23.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 1.63G/4.99G [01:17<02:21, 23.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 1.64G/4.99G [01:18<02:21, 23.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 1.65G/4.99G [01:18<02:20, 23.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 1.66G/4.99G [01:18<02:20, 23.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 1.67G/4.99G [01:19<02:19, 23.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 1.68G/4.99G [01:19<02:19, 23.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 1.69G/4.99G [01:20<02:20, 23.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 1.70G/4.99G [01:20<02:19, 23.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 1.71G/4.99G [01:21<02:18, 23.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 1.72G/4.99G [01:21<02:18, 23.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 1.73G/4.99G [01:22<02:20, 23.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 1.74G/4.99G [01:22<02:19, 23.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 1.75G/4.99G [01:22<02:19, 23.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 1.76G/4.99G [01:23<02:17, 23.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 1.77G/4.99G [01:23<02:16, 23.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 1.78G/4.99G [01:24<02:16, 23.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 1.79G/4.99G [01:24<02:16, 23.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 1.80G/4.99G [01:25<02:15, 23.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 1.81G/4.99G [01:25<02:14, 23.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 1.82G/4.99G [01:26<02:14, 23.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 1.84G/4.99G [01:26<02:14, 23.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 1.85G/4.99G [01:26<02:13, 23.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 1.86G/4.99G [01:27<02:13, 23.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 1.87G/4.99G [01:27<02:13, 23.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 1.88G/4.99G [01:28<02:12, 23.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 1.89G/4.99G [01:28<02:11, 23.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 1.90G/4.99G [01:29<02:10, 23.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 1.91G/4.99G [01:29<02:10, 23.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 1.92G/4.99G [01:30<02:09, 23.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 1.93G/4.99G [01:30<02:08, 23.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 1.94G/4.99G [01:30<02:08, 23.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 1.95G/4.99G [01:31<02:08, 23.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 1.96G/4.99G [01:31<02:07, 23.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 1.97G/4.99G [01:32<02:07, 23.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 1.98G/4.99G [01:32<02:07, 23.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 1.99G/4.99G [01:33<02:05, 23.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 2.00G/4.99G [01:33<02:05, 23.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 2.01G/4.99G [01:34<02:05, 23.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 2.02G/4.99G [01:34<02:04, 23.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 2.03G/4.99G [01:34<02:04, 23.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 2.04G/4.99G [01:35<02:03, 23.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 2.06G/4.99G [01:35<02:03, 23.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 2.07G/4.99G [01:36<02:03, 23.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 2.08G/4.99G [01:36<02:02, 23.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 2.09G/4.99G [01:37<02:02, 23.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 2.10G/4.99G [01:37<02:02, 23.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 2.11G/4.99G [01:38<02:01, 23.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 2.12G/4.99G [01:38<02:00, 23.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 2.13G/4.99G [01:39<02:10, 21.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 2.14G/4.99G [01:39<01:56, 24.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 2.15G/4.99G [01:39<01:57, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 2.16G/4.99G [01:40<01:57, 24.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 2.17G/4.99G [01:40<01:57, 24.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 2.18G/4.99G [01:41<01:57, 23.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 2.19G/4.99G [01:41<01:57, 23.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 2.20G/4.99G [01:41<01:56, 23.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 2.21G/4.99G [01:42<01:58, 23.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 2.22G/4.99G [01:43<02:32, 18.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 2.23G/4.99G [01:44<02:38, 17.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 2.24G/4.99G [01:44<02:59, 15.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 2.25G/4.99G [01:45<03:13, 14.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 2.26G/4.99G [01:46<03:07, 14.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 2.28G/4.99G [01:47<03:18, 13.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 2.29G/4.99G [01:47<03:09, 14.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 2.30G/4.99G [01:48<03:04, 14.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 2.31G/4.99G [01:49<03:14, 13.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 2.32G/4.99G [01:50<03:06, 14.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 2.33G/4.99G [01:50<03:00, 14.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 2.34G/4.99G [01:51<02:56, 15.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 2.35G/4.99G [01:52<03:08, 14.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 2.36G/4.99G [01:53<03:01, 14.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 2.37G/4.99G [01:53<02:56, 14.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 2.38G/4.99G [01:54<03:07, 13.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 2.39G/4.99G [01:55<03:00, 14.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 2.40G/4.99G [01:55<02:54, 14.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 2.41G/4.99G [01:56<02:51, 15.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 2.42G/4.99G [01:57<03:02, 14.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 2.43G/4.99G [01:58<02:55, 14.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 2.44G/4.99G [01:58<02:50, 14.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 2.45G/4.99G [01:59<02:47, 15.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 2.46G/4.99G [02:00<02:45, 15.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 2.47G/4.99G [02:00<02:42, 15.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 2.49G/4.99G [02:01<02:40, 15.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 2.50G/4.99G [02:02<02:39, 15.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 2.51G/4.99G [02:02<02:37, 15.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 2.52G/4.99G [02:03<02:37, 15.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 2.53G/4.99G [02:03<02:27, 16.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 2.54G/4.99G [02:04<02:21, 17.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 2.55G/4.99G [02:05<02:24, 16.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 2.56G/4.99G [02:05<02:11, 18.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 2.57G/4.99G [02:06<02:15, 17.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 2.58G/4.99G [02:06<02:06, 19.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 2.59G/4.99G [02:07<01:58, 20.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 2.60G/4.99G [02:07<01:53, 21.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 2.61G/4.99G [02:08<01:49, 21.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 2.62G/4.99G [02:08<01:45, 22.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 2.63G/4.99G [02:08<01:43, 22.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 2.64G/4.99G [02:09<01:41, 23.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 2.65G/4.99G [02:09<01:40, 23.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 2.66G/4.99G [02:10<01:39, 23.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 2.67G/4.99G [02:10<01:41, 22.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 2.68G/4.99G [02:11<01:39, 23.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 2.69G/4.99G [02:11<01:38, 23.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 2.71G/4.99G [02:12<01:37, 23.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 2.72G/4.99G [02:12<01:36, 23.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 2.73G/4.99G [02:12<01:35, 23.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 2.74G/4.99G [02:13<01:35, 23.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 2.75G/4.99G [02:13<01:37, 23.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 2.76G/4.99G [02:14<01:35, 23.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 2.77G/4.99G [02:14<01:34, 23.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 2.78G/4.99G [02:15<01:33, 23.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 2.79G/4.99G [02:15<01:32, 23.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 2.80G/4.99G [02:16<01:31, 23.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 2.81G/4.99G [02:16<01:33, 23.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 2.82G/4.99G [02:16<01:31, 23.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 2.83G/4.99G [02:17<01:32, 23.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 2.84G/4.99G [02:17<01:30, 23.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 2.85G/4.99G [02:18<01:29, 23.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 2.86G/4.99G [02:18<01:29, 23.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 2.87G/4.99G [02:19<01:28, 23.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 2.88G/4.99G [02:19<01:27, 24.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 2.89G/4.99G [02:19<01:27, 24.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 2.90G/4.99G [02:20<01:26, 24.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 2.92G/4.99G [02:20<01:25, 24.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 2.93G/4.99G [02:21<01:25, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 2.94G/4.99G [02:21<01:24, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 2.95G/4.99G [02:22<01:24, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 2.96G/4.99G [02:22<01:23, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 2.97G/4.99G [02:23<01:23, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 2.98G/4.99G [02:23<01:23, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 2.99G/4.99G [02:23<01:22, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 3.00G/4.99G [02:24<01:22, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 3.01G/4.99G [02:24<01:21, 24.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 3.02G/4.99G [02:25<01:21, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 3.03G/4.99G [02:25<01:20, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 3.04G/4.99G [02:26<01:20, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 3.05G/4.99G [02:26<01:19, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 3.06G/4.99G [02:26<01:19, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 3.07G/4.99G [02:27<01:19, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 3.08G/4.99G [02:27<01:18, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 3.09G/4.99G [02:28<01:18, 24.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 3.10G/4.99G [02:28<01:18, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 3.11G/4.99G [02:29<01:17, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 3.12G/4.99G [02:29<01:17, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 3.14G/4.99G [02:29<01:16, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 3.15G/4.99G [02:30<01:16, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 3.16G/4.99G [02:30<01:15, 24.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 3.17G/4.99G [02:31<01:25, 21.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 3.18G/4.99G [02:31<01:12, 25.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 3.19G/4.99G [02:32<01:12, 24.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 3.20G/4.99G [02:32<01:12, 24.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 3.21G/4.99G [02:33<01:12, 24.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 3.22G/4.99G [02:33<01:12, 24.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 3.23G/4.99G [02:33<01:12, 24.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 3.24G/4.99G [02:34<01:13, 23.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 3.25G/4.99G [02:34<01:10, 24.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 3.26G/4.99G [02:35<01:11, 24.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 3.27G/4.99G [02:35<01:10, 24.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 3.28G/4.99G [02:36<01:10, 24.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 3.29G/4.99G [02:36<01:09, 24.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 3.30G/4.99G [02:36<01:09, 24.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 3.31G/4.99G [02:37<01:09, 24.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 3.32G/4.99G [02:37<01:08, 24.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 3.33G/4.99G [02:38<01:08, 24.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 3.34G/4.99G [02:38<01:07, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 3.36G/4.99G [02:39<01:07, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 3.37G/4.99G [02:39<01:07, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 3.38G/4.99G [02:39<01:06, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 3.39G/4.99G [02:40<01:06, 24.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 3.40G/4.99G [02:40<01:05, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 3.41G/4.99G [02:41<01:05, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 3.42G/4.99G [02:41<01:07, 23.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 3.43G/4.99G [02:42<01:03, 24.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 3.44G/4.99G [02:42<01:03, 24.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 3.45G/4.99G [02:42<01:03, 24.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 3.46G/4.99G [02:43<01:02, 24.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 3.47G/4.99G [02:43<01:02, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 3.48G/4.99G [02:44<01:02, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 3.49G/4.99G [02:44<01:01, 24.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 3.50G/4.99G [02:45<01:01, 24.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 3.51G/4.99G [02:45<01:01, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 3.52G/4.99G [02:46<01:00, 24.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 3.53G/4.99G [02:46<01:00, 24.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 3.54G/4.99G [02:46<00:59, 24.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 3.55G/4.99G [02:47<00:59, 24.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 3.57G/4.99G [02:47<00:58, 24.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 3.58G/4.99G [02:48<00:58, 24.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 3.59G/4.99G [02:48<00:57, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 3.60G/4.99G [02:49<00:57, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 3.61G/4.99G [02:49<00:57, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 3.62G/4.99G [02:49<00:56, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 3.63G/4.99G [02:50<00:56, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 3.64G/4.99G [02:50<00:55, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 3.65G/4.99G [02:51<00:55, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 3.66G/4.99G [02:51<00:54, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 3.67G/4.99G [02:52<00:54, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 3.68G/4.99G [02:52<00:54, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 3.69G/4.99G [02:52<00:53, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 3.70G/4.99G [02:53<00:53, 24.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 3.71G/4.99G [02:53<00:52, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 3.72G/4.99G [02:54<00:52, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 3.73G/4.99G [02:54<00:52, 24.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 3.74G/4.99G [02:55<00:51, 24.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 3.75G/4.99G [02:55<00:51, 24.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 3.76G/4.99G [02:56<00:51, 24.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 3.77G/4.99G [02:56<00:50, 23.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 3.79G/4.99G [02:56<00:50, 23.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 3.80G/4.99G [02:57<00:49, 24.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 3.81G/4.99G [02:57<00:49, 24.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 3.82G/4.99G [02:58<00:48, 24.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 3.83G/4.99G [02:58<00:48, 24.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 3.84G/4.99G [02:59<00:47, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 3.85G/4.99G [02:59<00:47, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 3.86G/4.99G [02:59<00:46, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 3.87G/4.99G [03:00<00:46, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 3.88G/4.99G [03:00<00:45, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 3.89G/4.99G [03:01<00:45, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 3.90G/4.99G [03:01<00:44, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 3.91G/4.99G [03:02<00:44, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 3.92G/4.99G [03:02<00:44, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 3.93G/4.99G [03:02<00:43, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 3.94G/4.99G [03:03<00:43, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 3.95G/4.99G [03:03<00:42, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 3.96G/4.99G [03:04<00:42, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 3.97G/4.99G [03:04<00:41, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 3.98G/4.99G [03:05<00:41, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 4.00G/4.99G [03:05<00:41, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 4.01G/4.99G [03:05<00:40, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 4.02G/4.99G [03:06<00:40, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 4.03G/4.99G [03:06<00:39, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 4.04G/4.99G [03:07<00:39, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 4.05G/4.99G [03:07<00:39, 24.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 4.06G/4.99G [03:08<00:38, 24.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 4.07G/4.99G [03:08<00:38, 24.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 4.08G/4.99G [03:09<00:37, 24.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 4.09G/4.99G [03:09<00:37, 24.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 4.10G/4.99G [03:09<00:36, 24.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 4.11G/4.99G [03:10<00:36, 24.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 4.12G/4.99G [03:10<00:35, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 4.13G/4.99G [03:11<00:35, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 4.14G/4.99G [03:11<00:34, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 4.15G/4.99G [03:12<00:34, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 4.16G/4.99G [03:12<00:34, 24.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 4.17G/4.99G [03:12<00:33, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 4.18G/4.99G [03:13<00:33, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 4.19G/4.99G [03:13<00:32, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 4.20G/4.99G [03:14<00:32, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 4.22G/4.99G [03:14<00:31, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 4.23G/4.99G [03:15<00:31, 24.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 4.24G/4.99G [03:15<00:31, 24.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 4.25G/4.99G [03:15<00:30, 24.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 4.26G/4.99G [03:16<00:30, 24.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 4.27G/4.99G [03:16<00:29, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 4.28G/4.99G [03:17<00:29, 24.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 4.29G/4.99G [03:17<00:28, 24.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 4.30G/4.99G [03:18<00:28, 24.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 4.31G/4.99G [03:18<00:28, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 4.32G/4.99G [03:19<00:27, 24.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 4.33G/4.99G [03:19<00:27, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 4.34G/4.99G [03:19<00:26, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 4.35G/4.99G [03:20<00:26, 24.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 4.36G/4.99G [03:20<00:26, 23.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 4.37G/4.99G [03:21<00:25, 24.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 4.38G/4.99G [03:21<00:24, 24.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 4.39G/4.99G [03:22<00:24, 24.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 4.40G/4.99G [03:22<00:24, 24.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 4.41G/4.99G [03:22<00:23, 24.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 4.42G/4.99G [03:23<00:23, 24.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 4.44G/4.99G [03:23<00:22, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 4.45G/4.99G [03:24<00:22, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 4.46G/4.99G [03:24<00:21, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 4.47G/4.99G [03:25<00:21, 24.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 4.48G/4.99G [03:25<00:21, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 4.49G/4.99G [03:25<00:20, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 4.50G/4.99G [03:26<00:20, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 4.51G/4.99G [03:26<00:19, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 4.52G/4.99G [03:27<00:19, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 4.53G/4.99G [03:27<00:18, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 4.54G/4.99G [03:28<00:18, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 4.55G/4.99G [03:28<00:18, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 4.56G/4.99G [03:28<00:17, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 4.57G/4.99G [03:29<00:17, 24.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 4.58G/4.99G [03:29<00:16, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 4.59G/4.99G [03:30<00:16, 24.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 4.60G/4.99G [03:30<00:15, 24.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 4.61G/4.99G [03:31<00:15, 24.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 4.62G/4.99G [03:31<00:15, 24.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 4.63G/4.99G [03:32<00:14, 24.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 4.65G/4.99G [03:32<00:14, 24.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 4.66G/4.99G [03:32<00:13, 24.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 4.67G/4.99G [03:33<00:13, 24.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 4.68G/4.99G [03:33<00:12, 24.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 4.69G/4.99G [03:34<00:12, 24.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 4.70G/4.99G [03:34<00:12, 24.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 4.71G/4.99G [03:35<00:11, 24.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 4.72G/4.99G [03:35<00:11, 24.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 4.73G/4.99G [03:35<00:10, 24.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 4.74G/4.99G [03:36<00:10, 24.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 4.75G/4.99G [03:36<00:09, 24.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 4.76G/4.99G [03:37<00:09, 24.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 4.77G/4.99G [03:37<00:08, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 4.78G/4.99G [03:38<00:08, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 4.79G/4.99G [03:38<00:08, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 4.80G/4.99G [03:38<00:07, 24.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 4.81G/4.99G [03:39<00:07, 24.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 4.82G/4.99G [03:39<00:06, 24.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 4.83G/4.99G [03:40<00:06, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 4.84G/4.99G [03:40<00:05, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 4.85G/4.99G [03:41<00:05, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 4.87G/4.99G [03:41<00:05, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 4.88G/4.99G [03:42<00:04, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 4.89G/4.99G [03:42<00:04, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 4.90G/4.99G [03:42<00:03, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 4.91G/4.99G [03:43<00:03, 24.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 4.92G/4.99G [03:43<00:02, 24.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 4.93G/4.99G [03:44<00:02, 24.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 4.94G/4.99G [03:44<00:02, 24.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 4.95G/4.99G [03:45<00:01, 24.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 4.96G/4.99G [03:45<00:01, 24.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors: 100% 4.97G/4.99G [03:45<00:00, 23.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors: 100% 4.98G/4.99G [03:46<00:00, 24.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors: 100% 4.99G/4.99G [03:46<00:00, 22.0MB/s]\n",
            "Fetching 2 files: 100% 2/2 [03:47<00:00, 113.64s/it]\n",
            "Loading checkpoint shards: 100% 2/2 [00:00<00:00,  9.60it/s]\n",
            "generation_config.json: 100% 168/168 [00:00<00:00, 1.24MB/s]\n",
            "tokenizer_config.json: 100% 46.9k/46.9k [00:00<00:00, 13.1MB/s]\n",
            "tokenizer.model: 100% 4.24M/4.24M [00:00<00:00, 91.3MB/s]\n",
            "tokenizer.json: 100% 17.5M/17.5M [00:00<00:00, 288MB/s]\n",
            "special_tokens_map.json: 100% 555/555 [00:00<00:00, 4.49MB/s]\n",
            "Device set to use cuda\n",
            "2025-04-22 18:20:40.043 Examining the path of torch.classes raised:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/web/bootstrap.py\", line 347, in run\n",
            "    if asyncio.get_running_loop().is_running():\n",
            "       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: no running event loop\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 217, in get_module_paths\n",
            "    potential_paths = extract_paths(module)\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 210, in <lambda>\n",
            "    lambda m: list(m.__path__._path),\n",
            "                   ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_classes.py\", line 13, in __getattr__\n",
            "    proxy = torch._C._get_custom_class_python_wrapper(self.name, attr)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: Tried to instantiate class '__path__._path', but it does not exist! Ensure that it is registered via torch::class_\n",
            "NLTK Punkt data checked/downloaded.\n",
            "Database 'chat_feedback.db' initialized successfully.\n",
            "NLTK Punkt data checked/downloaded.\n",
            "Database 'chat_feedback.db' initialized successfully.\n",
            "Generated response in 22.22s\n",
            "NLTK Punkt data checked/downloaded.\n",
            "Database 'chat_feedback.db' initialized successfully.\n",
            "NLTK Punkt data checked/downloaded.\n",
            "Database 'chat_feedback.db' initialized successfully.\n",
            "2025-04-22 18:22:56.058 Examining the path of torch.classes raised:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/web/bootstrap.py\", line 347, in run\n",
            "    if asyncio.get_running_loop().is_running():\n",
            "       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: no running event loop\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 217, in get_module_paths\n",
            "    potential_paths = extract_paths(module)\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 210, in <lambda>\n",
            "    lambda m: list(m.__path__._path),\n",
            "                   ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_classes.py\", line 13, in __getattr__\n",
            "    proxy = torch._C._get_custom_class_python_wrapper(self.name, attr)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: Tried to instantiate class '__path__._path', but it does not exist! Ensure that it is registered via torch::class_\n",
            "NLTK Punkt data checked/downloaded.\n",
            "Database 'chat_feedback.db' initialized successfully.\n",
            "NLTK Punkt data checked/downloaded.\n",
            "Database 'chat_feedback.db' initialized successfully.\n",
            "NLTK Punkt data checked/downloaded.\n",
            "Database 'chat_feedback.db' initialized successfully.\n",
            "\u001b[34m  Stopping...\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "public_url = ngrok.connect(8501).public_url\n",
        "print(f\"公開URL: {public_url}\")\n",
        "!streamlit run app.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mq1O5jz6nN1B"
      },
      "source": [
        "アプリケーションの機能としては、チャット機能や履歴閲覧があります。\n",
        "\n",
        "これらの機能を実現するためには、StreamlitによるUI部分だけではなく、SQLiteを使用したチャット履歴の保存やLLMのモデルを呼び出した推論などの処理を組み合わせることで実現しています。\n",
        "\n",
        "- **`app.py`**: アプリケーションのエントリーポイント。チャット機能、履歴閲覧、サンプルデータ管理のUIを提供します。\n",
        "- **`ui.py`**: チャットページや履歴閲覧ページなど、アプリケーションのUIロジックを管理します。\n",
        "- **`llm.py`**: LLMモデルのロードとテキスト生成を行うモジュール。\n",
        "- **`database.py`**: SQLiteデータベースを使用してチャット履歴やフィードバックを保存・管理します。\n",
        "- **`metrics.py`**: BLEUスコアやコサイン類似度など、回答の評価指標を計算するモジュール。\n",
        "- **`data.py`**: サンプルデータの作成やデータベースの初期化を行うモジュール。\n",
        "- **`config.py`**: アプリケーションの設定（モデル名やデータベースファイル名）を管理します。\n",
        "- **`requirements.txt`**: このアプリケーションを実行するために必要なPythonパッケージ。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xvm8sWFPELSP"
      },
      "source": [
        "後片付けとして、使う必要のないngrokのトンネルを削除します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "WFJC2TmZELSP"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok\n",
        "ngrok.kill()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUXhIzV7ELSP"
      },
      "source": [
        "# 03_FastAPI\n",
        "\n",
        "ディレクトリ「03_FastAPI」に移動します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "4ejjDLxr3kfC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e3d8647-59ae-46d6-80bd-0376d59d0098"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/lecture-ai-engineering/day1/03_FastAPI\n"
          ]
        }
      ],
      "source": [
        "%cd /content/lecture-ai-engineering/day1/03_FastAPI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f45TDsNzELSQ"
      },
      "source": [
        "必要なライブラリをインストールします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "9uv6glCz5a7Z"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfrmE2VmELSQ"
      },
      "source": [
        "ngrokとhuggigfaceのトークンを使用して、認証を行います。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ELzWhMFORRIO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c834d3cb-90f5-4e2e-afaf-89c3a7f6a58e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n",
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: read).\n",
            "The token `read-token_AIeng_tokyoUT` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `read-token_AIeng_tokyoUT`\n"
          ]
        }
      ],
      "source": [
        "!ngrok authtoken $$NGROK_TOKEN\n",
        "!huggingface-cli login --token $$HUGGINGFACE_TOKEN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-wztc2CELSQ"
      },
      "source": [
        "アプリを起動します。\n",
        "\n",
        "「02_streamlit_app」から続けて「03_FastAPI」を実行している場合は、モデルのダウンロードが済んでいるため、すぐにサービスが立ち上がります。\n",
        "\n",
        "「03_FastAPI」のみを実行している場合は、初回の起動時にモデルのダウンロードが始まるので、モデルのダウンロードが終わるまで数分間待ちましょう。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "meQ4SwISn3IQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb4d1fa3-e967-4cc6-c878-0b34e0499b7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-22 18:26:50.347651: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1745346410.372881    5357 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1745346410.380757    5357 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-04-22 18:26:50.416946: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "モデル名を設定: google/gemma-2-2b-jpn-it\n",
            "/content/lecture-ai-engineering/day1/03_FastAPI/app.py:134: DeprecationWarning: \n",
            "        on_event is deprecated, use lifespan event handlers instead.\n",
            "\n",
            "        Read more about it in the\n",
            "        [FastAPI docs for Lifespan Events](https://fastapi.tiangolo.com/advanced/events/).\n",
            "        \n",
            "  @app.on_event(\"startup\")\n",
            "FastAPIエンドポイントを定義しました。\n",
            "アクティブなngrokトンネルはありません。\n",
            "ポート8501に新しいngrokトンネルを開いています...\n",
            "---------------------------------------------------------------------\n",
            "✅ 公開URL:   https://2e04-35-221-183-159.ngrok-free.app\n",
            "📖 APIドキュメント (Swagger UI): https://2e04-35-221-183-159.ngrok-free.app/docs\n",
            "---------------------------------------------------------------------\n",
            "(APIクライアントやブラウザからアクセスするためにこのURLをコピーしてください)\n",
            "\u001b[32mINFO\u001b[0m:     Started server process [\u001b[36m5357\u001b[0m]\n",
            "\u001b[32mINFO\u001b[0m:     Waiting for application startup.\n",
            "load_model_task: モデルの読み込みを開始...\n",
            "使用デバイス: cuda\n",
            "Loading checkpoint shards: 100% 2/2 [00:00<00:00, 13.52it/s]\n",
            "Device set to use cuda\n",
            "モデル 'google/gemma-2-2b-jpn-it' の読み込みに成功しました\n",
            "load_model_task: モデルの読み込みが完了しました。\n",
            "起動時にモデルの初期化が完了しました。\n",
            "\u001b[32mINFO\u001b[0m:     Application startup complete.\n",
            "\u001b[32mINFO\u001b[0m:     Uvicorn running on \u001b[1mhttp://0.0.0.0:8501\u001b[0m (Press CTRL+C to quit)\n",
            "\u001b[32mINFO\u001b[0m:     118.238.247.51:0 - \"\u001b[1mGET / HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     118.238.247.51:0 - \"\u001b[1mGET /favicon.ico HTTP/1.1\u001b[0m\" \u001b[31m404 Not Found\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     118.238.247.51:0 - \"\u001b[1mGET / HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     118.238.247.51:0 - \"\u001b[1mGET / HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     118.238.247.51:0 - \"\u001b[1mGET /docs HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     118.238.247.51:0 - \"\u001b[1mGET /openapi.json HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     Shutting down\n",
            "\u001b[32mINFO\u001b[0m:     Waiting for application shutdown.\n",
            "\u001b[32mINFO\u001b[0m:     Application shutdown complete.\n",
            "\u001b[32mINFO\u001b[0m:     Finished server process [\u001b[36m5357\u001b[0m]\n",
            "\n",
            "サーバープロセスが終了しました。\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-1' coro=<Server.serve() done, defined at /usr/local/lib/python3.11/dist-packages/uvicorn/server.py:68> exception=KeyboardInterrupt()>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/main.py\", line 580, in run\n",
            "    server.run()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/server.py\", line 66, in run\n",
            "    return asyncio.run(self.serve(sockets=sockets))\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/nest_asyncio.py\", line 30, in run\n",
            "    return loop.run_until_complete(task)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/nest_asyncio.py\", line 92, in run_until_complete\n",
            "    self._run_once()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/nest_asyncio.py\", line 133, in _run_once\n",
            "    handle._run()\n",
            "  File \"/usr/lib/python3.11/asyncio/events.py\", line 84, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/usr/lib/python3.11/asyncio/tasks.py\", line 360, in __wakeup\n",
            "    self.__step()\n",
            "  File \"/usr/lib/python3.11/asyncio/tasks.py\", line 277, in __step\n",
            "    result = coro.send(None)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/server.py\", line 69, in serve\n",
            "    with self.capture_signals():\n",
            "  File \"/usr/lib/python3.11/contextlib.py\", line 144, in __exit__\n",
            "    next(self.gen)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/uvicorn/server.py\", line 330, in capture_signals\n",
            "    signal.raise_signal(captured_signal)\n",
            "KeyboardInterrupt\n"
          ]
        }
      ],
      "source": [
        "!python app.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLubjIhbELSR"
      },
      "source": [
        "FastAPIが起動すると、APIとクライアントが通信するためのURL（エンドポイント）が作られます。\n",
        "\n",
        "URLが作られるのと合わせて、Swagger UIというWebインターフェースが作られます。\n",
        "\n",
        "Swagger UIにアクセスすることで、APIの仕様を確認できたり、APIをテストすることができます。\n",
        "\n",
        "Swagger UIを利用することで、APIを通してLLMを動かしてみましょう。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgumW3mGELSR"
      },
      "source": [
        "後片付けとして、使う必要のないngrokのトンネルを削除します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RJymTZio-WPJ"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok\n",
        "ngrok.kill()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}